{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tesina Data Spaces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxqVaqsrRrFLbTBCI1ZI+Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimoneDutto/Hate-Speech-TwitterBot/blob/master/HateSpeech_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiPo5jQrReE6",
        "colab_type": "text"
      },
      "source": [
        "## Tesina Data Spaces\n",
        "Considerazioni: stopword, lemmatize, hashtag, multinaive, logistic regression, grammar error\n",
        "https://towardsdatascience.com/detecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6 \n",
        "https://pypi.org/project/grammar-check/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxNlCgNlUQGg",
        "colab_type": "text"
      },
      "source": [
        "### Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNLSxYQ2k0Dx",
        "colab_type": "code",
        "outputId": "e83a2e24-3a3b-4375-ef5b-f171da23ecf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "pip install --user -U nltk\n",
        "pip install --user gingerit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gingerit\n",
            "  Downloading https://files.pythonhosted.org/packages/78/af/e537e83cbd83b60ca94530a42a0ad9b389bad50c98b0518118e653475eeb/gingerit-0.8.0-py3-none-any.whl\n",
            "Collecting requests<3.0,>=2.22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (2019.11.28)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (2.8)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, gingerit\n",
            "Successfully installed gingerit-0.8.0 requests-2.23.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4KC5oOgRZH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "e48ffee3-697d-4f45-f548-546e72a33069"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!7z x /content/gdrive/My\\ Drive/Data\\ Spaces/twitter-sentiment-analysis-hatred-speech.zip \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/gdrive/My Drive/Data Spaces/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 1982527 bytes (1937 KiB)\n",
            "\n",
            "Extracting archive: /content/gdrive/My Drive/Data Spaces/twitter-sentiment-analysis-hatred-speech.zip\n",
            "--\n",
            "Path = /content/gdrive/My Drive/Data Spaces/twitter-sentiment-analysis-hatred-speech.zip\n",
            "Type = zip\n",
            "Physical Size = 1982527\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     ./test.csv\n",
            "  Size:     1635543 bytes (1598 KiB)\n",
            "  Modified: 2019-10-17 08:06:28\n",
            "with the file from archive:\n",
            "  Path:     test.csv\n",
            "  Size:     1635543 bytes (1598 KiB)\n",
            "  Modified: 2019-10-17 08:06:28\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? q\n",
            "\n",
            "Archives with Errors: 1\n",
            "\n",
            "\n",
            "\n",
            "Break signaled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmQqA96g6b6_",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azh8uj_d6baY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df1 = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "print(\"Hatred labeled: {}\\nNon-hatred labeled: {}\".format(\n",
        "    (df1.label == 1).sum(),\n",
        "    (df1.label == 0).sum()\n",
        "))\n",
        "#Missing Values If Any\n",
        "df1.isna().sum()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dko6CQmbgWEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing different libraries for analysis, processing and classification\n",
        "import nltk\n",
        "from sklearn import re #regular expression for text processing\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer #word stemmer class\n",
        "lemma = WordNetLemmatizer()\n",
        "# vectorizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression #classification model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score # performance evaluation criteria\n",
        "#grammar-check\n",
        "from gingerit.gingerit import GingerIt\n",
        "\n",
        "text = 'The smelt of fliwers bring back memories.'\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "stopwords.add('amp') #amp doesnt mean anything, it is just the formatting label\n",
        "\n",
        "def normalizer(tweet):\n",
        "    tweets = \" \".join(filter(lambda x: x[0]!= '@' , tweet.split()))\n",
        "    tweets = re.sub('[^a-zA-Z]', ' ', tweets)\n",
        "    tweets = tweets.lower()\n",
        "    tweets = tweets.split()\n",
        "    tweets = [word for word in tweets if not word in stopwords]\n",
        "    tweets = [lemma.lemmatize(word) for word in tweets]\n",
        "    tweets = \" \".join(tweets)\n",
        "    return tweets\n",
        "\n",
        "def extract_hashtag(tweet):\n",
        "    tweets = \" \".join(filter(lambda x: x[0]== '#', tweet.split()))\n",
        "    tweets = re.sub('[^a-zA-Z]',' ',  tweets)\n",
        "    tweets = tweets.lower()\n",
        "    tweets = [lemma.lemmatize(word) for word in tweets]\n",
        "    tweets = \"\".join(tweets)\n",
        "    return tweets\n",
        "def mentions(tweet):\n",
        "    tweets = \" \".join(filter(lambda x: x[0]== '@' , tweet.split()))\n",
        "    return len(tweets)\n",
        "\n",
        "def grammar_check(tweet):\n",
        "    tweets = \" \".join(filter(lambda x: x[0]!= '@' , tweet.split()))\n",
        "    tweets = re.sub('[^a-zA-Z]', ' ', tweets)\n",
        "    tweets = tweets.lower()\n",
        "    tweets = tweets.split()\n",
        "    tweets = [word for word in tweets if not word in stopwords]\n",
        "    tweets = \" \".join(tweets)\n",
        "    #print(tweets)\n",
        "    parser = GingerIt()\n",
        "    ginger_grammar_results = parser.parse(tweets)\n",
        "    #pprint.pprint(ginger_grammar_results)\n",
        "    ginger_corrections = ginger_grammar_results['corrections']\n",
        "    return int(len(ginger_corrections))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdsPGQsCgk1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1['normalized_text'] = df1.tweet.apply(normalizer)\n",
        "df1['hashtag'] = df1.tweet.apply(extract_hashtag)\n",
        "df1['mentions'] = df1.tweet.apply(mentions)\n",
        "#df1['grammar_check'] = df1.tweet.iloc[:100].apply(grammar_check)\n",
        "df1['grammar_check'] = pd.read_csv('output.csv')['grammar_check']\n",
        "# print(df1['normalized_text'].head)\n",
        "# print(df1['hashtag'].head())\n",
        "print(df1['mentions'].head())\n",
        "print(df1['grammar_check'].head())\n",
        "df1.to_csv('output.csv', columns = [\"grammar_check\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0tTuRW_oILI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import FreqDist \n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "all_hashtags = FreqDist(list(' '.join(df1.hashtag.values).split())).most_common(10)\n",
        "hatred_hashtags = FreqDist(list(' '.join(df1[df1.label==1].hashtag.values).split())).most_common(10)\n",
        "plt.figure(figsize=(14, 6))\n",
        "ax = plt.subplot(121)\n",
        "pd.DataFrame(all_hashtags, columns=['hashtag', 'Count']).set_index('hashtag').plot.barh(ax=ax, fontsize=12)\n",
        "plt.xlabel('# occurrences')\n",
        "plt.title('Hashtags in all tweets', size=13)\n",
        "ax = plt.subplot(122)\n",
        "pd.DataFrame(hatred_hashtags, columns=['hashtag', 'Count']).set_index('hashtag').plot.barh(ax=ax, fontsize=12)\n",
        "plt.xlabel('# occurrences')\n",
        "plt.ylabel('')\n",
        "plt.title('Hashtags in hatred tweets', size=13)\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "all_words = FreqDist(list(' '.join(df1.normalized_text.values).split())).most_common(20)\n",
        "hatred_words = FreqDist(list(' '.join(df1[df1.label==1].normalized_text.values).split())).most_common(20)\n",
        "plt.figure(figsize=(14, 6))\n",
        "ax = plt.subplot(121)\n",
        "pd.DataFrame(all_words, columns=['word', 'Count']).set_index('word').plot.barh(ax=ax, fontsize=12)\n",
        "plt.xlabel('# occurrences')\n",
        "plt.title('Words in all tweets', size=13)\n",
        "ax = plt.subplot(122)\n",
        "pd.DataFrame(hatred_words, columns=['word', 'Count']).set_index('word').plot.barh(ax=ax, fontsize=12)\n",
        "plt.xlabel('# occurrences')\n",
        "plt.ylabel('')\n",
        "plt.title('Words in hatred tweets', size=13)\n",
        "plt.show()\n",
        "\n",
        "print(\"Number of mentions: {}\\nNumber of tweets having a mention: {}\\nCorrelation with label: {}\".format(\n",
        "    df1.mentions.sum(),\n",
        "    len(df1[df1.mentions > 0]),\n",
        "    np.corrcoef(df1.mentions, df1.label)[0][1]\n",
        "))\n",
        "print(df1['grammar_check'].iloc[:100])\n",
        "print(\"Number of grammar errors: {}\\nNumber of tweets having a grammar error: {}\\nCorrelation with label: {}\".format(\n",
        "    df1.grammar_check.iloc[:1000].sum(),\n",
        "    len(df1[df1.grammar_check > 0]),\n",
        "    np.corrcoef(df1.grammar_check.iloc[:1000], df1.label.iloc[:1000])[0][1]\n",
        "))\n",
        "# non-relavant\n",
        "df1.drop('mentions', axis=1, inplace=True)\n",
        "df1.drop('grammar_check', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRPS316kDNSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "d5e318fd-690d-4af0-f5e9-97202ed2feec"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "trainp=df1[df1['label']==1]\n",
        "trainn=df1[df1['label']==0]\n",
        "#print(trainp.info())\n",
        "#trainn.info()\n",
        "\n",
        "train_imbalanced = df1\n",
        "from sklearn.utils import resample\n",
        "df_majority = df1[df1.label==0]\n",
        "df_minority = df1[df1.label==1]\n",
        " \n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=len(df_majority),    # to match majority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "print(\"Before\")\n",
        "print(df1.label.value_counts())\n",
        "print(\"After\")\n",
        "print(df_upsampled.label.value_counts())\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_upsampled['normalized_text'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])\n",
        "\n",
        "vect = CountVectorizer()\n",
        "tf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\n",
        "tf_test=vect.transform(X_test)\n",
        "\n",
        "df_test['normalized_text'] = df_test.tweet.apply(normalizer)\n",
        "tf_test_nolabel=vect.transform(df_test.normalized_text)\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before\n",
            "0    29720\n",
            "1     2242\n",
            "Name: label, dtype: int64\n",
            "After\n",
            "1    29720\n",
            "0    29720\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xgl1UhDbByo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "df568dd0-4bb4-4e7b-f86d-461fc93ab38a"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "model = MultinomialNB()\n",
        "\n",
        "model.fit(X=tf_train,y=y_train)\n",
        "expected = y_test\n",
        "predicted=model.predict(tf_test)\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "#print(metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "plot_confusion_matrix(metrics.confusion_matrix(expected, predicted))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Figure size 432x288 with 1 Axes>,\n",
              " <matplotlib.axes._subplots.AxesSubplot at 0x7f18845876a0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}